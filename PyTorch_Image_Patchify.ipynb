{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME1LjmU9WmuN+dSuFplw4p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HardcoreBudget/PyTorch-Image-Patchify/blob/main/PyTorch_Image_Patchify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "phNGzejICOAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from PIL import Image\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "cK8_xBkECQui"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fDqJ3Xc6oo1"
      },
      "source": [
        "# Patchify"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbwC6EjqVCnR"
      },
      "source": [
        "## Custom Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GR85wGMhVHhW"
      },
      "outputs": [],
      "source": [
        "def custom_patchify(frame_in, crops_size, overlap_size = [0,0]):\n",
        "    patch_list = []\n",
        "    oversize_H = False\n",
        "    oversize_W = False\n",
        "    crops_size_H = crops_size[1]\n",
        "    crops_size_W = crops_size[0]\n",
        "    overlap_size_H = overlap_size[1]\n",
        "    overlap_size_W = overlap_size[0]\n",
        "    frame_in_H = frame_in.shape[-2]\n",
        "    frame_in_W = frame_in.shape[-1]\n",
        "    assert (crops_size_H >= 2 * overlap_size_H) and (crops_size_W >= 2 * overlap_size_W), \"Crops size should be at least 2x greater than overlap size\"\n",
        "    crops_per_row = 1\n",
        "    row_size = crops_size_H\n",
        "    while(row_size < frame_in_H):\n",
        "      row_size += (crops_size_H - overlap_size_H)\n",
        "      crops_per_row += 1\n",
        "\n",
        "    final_row_size = row_size - crops_size_H\n",
        "\n",
        "    crops_per_col = 1\n",
        "    col_size = crops_size_W\n",
        "    while(col_size < frame_in_W):\n",
        "      col_size += (crops_size_W - overlap_size_W)\n",
        "      crops_per_col += 1\n",
        "\n",
        "    final_col_size = col_size - crops_size_W\n",
        "\n",
        "    oversize_value_H = (int) (frame_in_H - final_row_size)\n",
        "    oversize_value_W = (int) (frame_in_W - final_col_size)\n",
        "    if (oversize_value_H != 0):\n",
        "      oversize_H = True\n",
        "    if (oversize_value_W != 0):\n",
        "      oversize_W = True\n",
        "\n",
        "    top = 0\n",
        "    height = crops_size_H\n",
        "    for i in range(crops_per_row):\n",
        "\n",
        "      left = 0\n",
        "      crop = []\n",
        "      if(i == (crops_per_row - 1)):\n",
        "        if (oversize_H == True):\n",
        "          height = oversize_value_H\n",
        "        else:\n",
        "          height = crops_size_H\n",
        "\n",
        "      for j in range(crops_per_col):\n",
        "\n",
        "        if((j != (crops_per_col - 1)) or oversize_W == False):\n",
        "          width = crops_size_W\n",
        "        elif(oversize_W == True):\n",
        "          width = oversize_value_W\n",
        "\n",
        "        crop.append(TF.crop(frame_in, top, left, height, width)) ##top , Left , Height , Width)\n",
        "        left += crops_size_W - overlap_size_W\n",
        "\n",
        "      patch_list.append(crop)\n",
        "      top += crops_size_H - overlap_size_H\n",
        "\n",
        "    return patch_list, crops_per_row, crops_per_col\n",
        "\n",
        "def custom_unpatchify(patch_list, crops_per_row, crops_per_col, overlap_size = [0,0]):\n",
        "\n",
        "    overlap_size_H = overlap_size[1]\n",
        "    overlap_size_W = overlap_size[0]\n",
        "    unpatch_list = []\n",
        "    unpatch_list_W = []\n",
        "    unpatch_list_H = []\n",
        "    end_W = patch_list[0][0].shape[-1] - overlap_size_W\n",
        "    end_H = patch_list[0][0].shape[-2] - overlap_size_H\n",
        "\n",
        "    for i in range(crops_per_row):\n",
        "      crop_unpatch_list = []\n",
        "      for j in range(crops_per_col):\n",
        "        if(j == 0):\n",
        "          crop_W = 0\n",
        "        else:\n",
        "          crop_W = overlap_size_W\n",
        "\n",
        "        if(j != (crops_per_col - 1)):\n",
        "          crop_unpatch_list.append(patch_list[i][j][:, :, :, crop_W : end_W])\n",
        "        else:\n",
        "          crop_unpatch_list.append(patch_list[i][j][:, :, :, crop_W :])\n",
        "\n",
        "\n",
        "        if((j+1) < crops_per_col and overlap_size_W > 0):\n",
        "          overlapping_area_W = (patch_list[i][j][:, :, :,end_W : ] + \\\n",
        "                                patch_list[i][j + 1][:, :, :,  : overlap_size_W]) / 2\n",
        "          crop_unpatch_list.append(overlapping_area_W)\n",
        "\n",
        "      unpatch_list_W.append(torch.cat(crop_unpatch_list,-1))\n",
        "\n",
        "      if((i - 1) >= 0 and overlap_size_H > 0):\n",
        "        overlapping_area_H = (unpatch_list_W[i - 1][:, :, end_H :, :] + \\\n",
        "                              unpatch_list_W[i][:, :,  : overlap_size_H, :]) / 2\n",
        "        unpatch_list_H.append(overlapping_area_H)\n",
        "        if(i == 1):\n",
        "          unpatch_list_W[i - 1] = unpatch_list_W[i - 1][:, :, : end_H, :]\n",
        "\n",
        "        else:\n",
        "          unpatch_list_W[i - 1] = unpatch_list_W[i - 1][:, :, overlap_size_H : end_H, :]\n",
        "\n",
        "      if(i == (crops_per_row - 1)):\n",
        "        unpatch_list_W[i] = unpatch_list_W[i][:, :, overlap_size_H :, :]\n",
        "\n",
        "    for z in range(len(unpatch_list_W)):\n",
        "      unpatch_list.append(unpatch_list_W[z])\n",
        "      if(z < len(unpatch_list_H)):\n",
        "        unpatch_list.append(unpatch_list_H[z])\n",
        "\n",
        "    frame_out = torch.cat(unpatch_list,-2)\n",
        "\n",
        "    return frame_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc_EUNSWpnUB"
      },
      "source": [
        "## Grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LQlNX1PS6nef"
      },
      "outputs": [],
      "source": [
        "def grid_patchify(frame_in,crops_amount):\n",
        "    patch_list_top = []\n",
        "    patch_list_bottom = []\n",
        "    crops_per_row = (int) (crops_amount / 2)\n",
        "    oversize = False\n",
        "    if(frame_in.shape[-2] % crops_per_row != 0):\n",
        "        oversize = True\n",
        "        oversize_value = (int) (frame_in.shape[-2] - (crops_per_row - 1) * (frame_in.shape[-2]//crops_per_row))\n",
        "    y = (int) (frame_in.shape[-2]//crops_per_row)\n",
        "    x = (int) (frame_in.shape[-1]//2)\n",
        "    for i in range(crops_per_row):\n",
        "        if(i != (crops_per_row - 1) or oversize == False):\n",
        "            w=TF.crop(frame_in, i*y, 0,  y,  x) ##top , Left , Height , Width\n",
        "            patch_list_top.append(w)\n",
        "            w=TF.crop(frame_in, i*y, x,  y,  x) ##top , Left , Height , Width\n",
        "            patch_list_bottom.append(w)\n",
        "        elif(oversize):\n",
        "            w=TF.crop(frame_in, i*y, 0,  oversize_value,  x) ##top , Left , Height , Width\n",
        "            patch_list_top.append(w)\n",
        "            w=TF.crop(frame_in, i*y, x,  oversize_value,  x) ##top , Left , Height , Width\n",
        "            patch_list_bottom.append(w)\n",
        "\n",
        "    return patch_list_top,patch_list_bottom\n",
        "\n",
        "def grid_unpatchify(patch_list_T,patch_list_B):\n",
        "\n",
        "    frame_out_T=torch.cat(tuple(patch_list_T),-2)\n",
        "    frame_out_B=torch.cat(tuple(patch_list_B),-2)\n",
        "    frame_out = torch.cat((frame_out_T,frame_out_B),-1)\n",
        "    return frame_out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "rFyCLB1YBP9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/test.png\"\n",
        "\n",
        "transform_t = transforms.ToTensor()\n",
        "transform_i = transforms.ToPILImage()\n",
        "\n",
        "img = Image.open(Path(image_path)).convert(\"RGB\")\n",
        "img_t = transform_t(img).unsqueeze(0)\n",
        "\n",
        "print(img_t.shape)"
      ],
      "metadata": {
        "id": "2IfFWcUVB3PF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Patchify"
      ],
      "metadata": {
        "id": "d-g9PsQMBYol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crop_size = [384,384]\n",
        "overlap_size = [0,0]\n",
        "\n",
        "patch_list, crops_per_row, crops_per_col = custom_patchify(img_t, crop_size, overlap_size)\n",
        "frameout = custom_unpatchify(patch_list, crops_per_row, crops_per_col, overlap_size)\n",
        "\n",
        "print(frameout.shape)\n",
        "transform_i(frameout.squeeze(0))"
      ],
      "metadata": {
        "id": "QOq_5KtDBSZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grid patchify"
      ],
      "metadata": {
        "id": "K061YHasBcGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_crops = 4\n",
        "\n",
        "patch_list_T, patch_list_B = grid_patchify(img_t, number_of_crops)\n",
        "frameout = grid_unpatchify(patch_list_T,patch_list_B)\n",
        "\n",
        "print(frameout.shape)\n",
        "transform_i(frameout.squeeze(0))"
      ],
      "metadata": {
        "id": "NLSoHcd8BefO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}